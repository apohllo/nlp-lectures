{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tagowanie morfosyntaktyczne\n",
    "\n",
    "<br/>\n",
    "\n",
    "## dr in偶. Aleksander Smywiski-Pohl\n",
    "\n",
    "## apohllo@agh.edu.pl\n",
    "\n",
    "## http://apohllo.pl/dydaktyka/nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plan\n",
    "\n",
    "* **czci mowy i kategorie gramatyczne**\n",
    "* tagowanie morfosyntaktyczne\n",
    "* algorytmy tagowania\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img src=\"img/tagging.png\" />\n",
    "    <small>https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/</small>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Czci mowy - klasyfikacja tradycyjna\n",
    "\n",
    "* odmienne\n",
    "  * rzeczownik, np. *ko*\n",
    "  * przymiotnik, np. *twarda*\n",
    "  * czasownik, np. *gry藕*\n",
    "  * liczebnik, np. *siedem*\n",
    "  * zaimek (cz), np. *m贸j*\n",
    "  * przys贸wek, np. *szybko*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## &nbsp;\n",
    "\n",
    "* nieodmienne\n",
    "  * zaimek (cz), np. *tam*\n",
    "  * przyimek, np. *do*\n",
    "  * sp贸jnik, np. *i*\n",
    "  * wykrzyknik, np. *aha*\n",
    "  * partykua, np. *nie*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Czci mowy - klasy otwarte i zamknite\n",
    "\n",
    "* klasy otwarte: rzeczownik, czasownik, przymiotnik, przys贸wek\n",
    "* klasy zamknite: pozostae\n",
    "\n",
    "$\\rightarrow$ powstawanie nowych wyraz贸w zarezerwowane jest do klas otwartych, np. *iPhone*, *lockdown*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kategorie gramatyczne 1/2 w Narodowym Korpusie Jzyka Polskiego (NKJP)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center><img src=\"img/tagi-3-pl.png\" width=\"800px\"/></center>\n",
    "\n",
    "http://nkjp.pl/poliqarp/help/plse2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kategorie gramatyczne 2/2\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center><img src=\"img/tagi-4-pl.png\" width=\"750px\"></center>\n",
    "\n",
    "http://nkjp.pl/poliqarp/help/plse2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Klasy fleksyjne 1/2\n",
    "&nbsp;\n",
    "<center><img src=\"img/tagi-1-pl.png\" width=\"1500px\"/></center>\n",
    "\n",
    "http://nkjp.pl/poliqarp/help/plse2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Klasy fleksyjne 2/2\n",
    "\n",
    "&nbsp;\n",
    "<center><img src=\"img/tagi-2-pl.png\" width=\"1500px\"/></center>\n",
    "\n",
    "http://nkjp.pl/poliqarp/help/plse2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kompatybilno kategorii i klas\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center><img src=\"img/kategorie-macierz.png\" width=\"1500px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Klasy fleksyjne Universal Dependencies 2.0\n",
    "\n",
    "* ADJ: adjective, np. *big*\n",
    "* ADV: adverb, np. *very*\n",
    "* AUX: auxiliary, np. *must*\n",
    "* CCONJ: coordinating conjunction, np. *and*\n",
    "* DET: determiner, np. *the*\n",
    "* INTJ: interjection, np. *psst*\n",
    "* NOUN: noun, np. *apple*\n",
    "* NUM: numeral, np. *one*\n",
    "* PART: particle, np. *not*\n",
    "\n",
    "https://universaldependencies.org/u/pos/all.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## &nbsp;\n",
    "\n",
    "\n",
    "* PRON: pronoun, np. *you*\n",
    "* PROPN: proper noun, np. *Mary*\n",
    "* PUNCT: punctuation, np. *!*\n",
    "* SCONJ: subordinating conjunction, np. *that*\n",
    "* SYM: symbol, np. \n",
    "* VERB: verb, np. *run*\n",
    "* X: other, np. *xfgh*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tagi w korpusie Penn Treebank\n",
    "\n",
    "&nbsp;\n",
    "<center><img src=\"img/english-tags.png\" width=\"1200px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plan\n",
    "\n",
    "* czci mowy i kategorie gramatyczne\n",
    "* **tagowanie morfosyntaktyczne**\n",
    "* algorytmy tagowania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Tagowanie morfosyntaktyczne\n",
    "\n",
    "<br/>\n",
    "\n",
    "```\n",
    "Partia           partia         subst:sg:nom:f\n",
    "polityczna       polityczny     adj:sg:nom:f:pos\n",
    "jest             by            fin:sg:ter:imperf\n",
    "dobrowoln       dobrowolny     adj:sg:inst:f:pos\n",
    "organizacj      organizacja    subst:sg:inst:f\n",
    ",                ,              interp\n",
    "wystpujc      wystpowa     pact:sg:inst:f:imperf:aff\n",
    "pod              pod            prep:inst:nwok\n",
    "okrelon        okrelony      adj:sg:inst:f:pos\n",
    "nazw            nazwa          subst:sg:inst:f\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Jest to zadanie nale偶ce do kategorii dezambiguacji, tzn. nale偶y wybra jedn z dostpnych mo偶liwoci.\n",
    "\n",
    "W opisie morfologicznym na pierwszym miejscu wystpuje klasa fleksyjna, a na pozostaych wartoci adekatnych kategorii gramatycznych.\n",
    "\n",
    "Liczba mo偶liwych kombinacji wartoci dla jzyka polskiego przekracza 1000. Dla jzyka angileskiego - w zale偶noci od tagsetu - Penn Treebank 45 tag贸w, korpus Browna 87 tag贸w. Wida wic, 偶e zadanie tagowania posiada znaczco r贸偶n trudnodla r贸偶nych jzyk贸w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Zastosowania tagowania morfosyntaktycznego\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* ulepszona lematyzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* ilociowa analiza korpus贸w pod wzgldem morfologii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* filtr dla wyra偶e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* informacja wejciowa dla wielu innych algorytm贸w NLP, np. \n",
    "  * jednostki nazewnicze\n",
    "  * parsing\n",
    "  * koreferencja\n",
    "  * klasyfikacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Przykady dezambiguacji\n",
    "\n",
    "Lewandowski nie strzeli 偶adnych **goli**.\n",
    "\n",
    "`subst:pl:gen:m2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "rzeczownik, liczba mnoga, dopeniacz, r. mski zwierzcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lewandowski **goli** si codziennie.\n",
    "\n",
    "`fin:sg:ter:imperf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "forma nieprzesza czasownika, liczba pojedynczy, 3 osoba, aspekt niedokonany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lewandowski i inni m偶czy藕ni na pla偶y nudyst贸w byli **goli**.\n",
    "\n",
    "`adj:pl:nom:m1:pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "przymiotnik, liczba mnoga, mianownik, r. mski osobowy, stopie r贸wny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Dopiero tagger KFTT osiga warto 97% poprawnoci tagowania - zbli偶on do jzyka angileskiego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plan\n",
    "\n",
    "* czci mowy i kategorie gramatyczne\n",
    "* tagowanie morfosyntaktyczne\n",
    "* **algorytmy tagowania**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Algorytmy tagowania\n",
    "\n",
    "* ukryty model Markowa (HMM)\n",
    "* model Markowa o maksymalnej entropii (MEMM)\n",
    "* warunkowe pola losowe (CRF)\n",
    "* sieci neuronowe (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## acuchy Markowa\n",
    "\n",
    "<center><img src=\"img/markow-chain.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Zao偶enie dla acucha Markowa 1-rzdu:\n",
    "\n",
    "$P(q_i=a|q_1 \\cdots q_{i-1}) = P(q_i=a|q_{i-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Definicja acucha Markowa 1-rzdu\n",
    "\n",
    "* $Q = q_1, q_2, \\cdots q_n$ - zbi贸r $N$ stan贸w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $A = q_{11}, q_{12}, q_{13}, \\cdots q_{nn}$ - macierz przejcia taka, 偶e $\\sum_{j=1}^{n} a_{ij} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\Pi = \\pi_1, \\pi_2, \\cdots \\pi_n$ - prawdopodobiestwo stan贸w pocztkowych, $\\sum _{i=1}^{n} \\pi_{i} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ukryty model Markowa 1-rzdu (HMM)\n",
    "\n",
    "<center><img src=\"img/hmm.png\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Przykad HMM\n",
    "\n",
    "<center><img src=\"img/hmm-example.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Definicja ukrytego modelu Markowa 1-rzdu\n",
    "\n",
    "* $Q = q_1, q_2, \\cdots q_n$ - zbi贸r $N$ stan贸w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $A = q_{11}, q_{12}, q_{13}, \\cdots q_{nn}$ - macierz przejcia taka, 偶e $\\sum_{j=1}^{n} a_{ij} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $O = o_1, o_2, o_3, \\cdots, o_T$ - sekwencja $T$ obserwacji,\n",
    "  kt贸re pochodz ze sownika $V = v_1, v_2, \\cdots, v_V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $B = b_i(o_t)$ - sekwencja prawdopodobiestw obserwacji (lub emisji), wyra偶ajcych \n",
    "  prawdopodobiestwo zaobserwowania obserwacji $o_t$ w stanie $q_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\Pi = \\pi_1, \\pi_2, \\cdots \\pi_n$ - prawdopodobiestwo stan贸w pocztkowych, $\\sum _{i=1}^{n} \\pi_{i} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Zao偶enia dla HMM\n",
    "\n",
    "* $P(q_i=a|q_1 \\cdots q_{i-1}) = P(q_i=a|q_{i-1})$ - wasno Markowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $P(o_i| q_1, q_2, \\cdots, q_T; o_1, o_2, \\cdots, o_i, \\cdots, o_T) = P(o_i|q_i)$ - niezale偶nowyj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tagowanie morfosyntaktyczne w oparciu o HMM\n",
    "\n",
    "\n",
    "* $P(t_i | t_{i-1})$ - prawdopodobiestwo wystpienia tagu $t_i$ po tagu $t_{i-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* przykad: *w szkole* - `subst` czsto wystpuje po `prep`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $P(t_i | t_{i-1}) \\cong \\frac{C(t_{i-1},t_i)}{C(t_{i-1})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $P(w_i | t_i)$ - prawdopodobiestwo emisji wyrazu $w_i$ dla tagu $t_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* przykad: *zaimek $\\rightarrow$ on* - `ppron3` ma du偶e prawdopodobiestwo \"wyemitowania\" zaimka \"on\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $P(w_i | t_i) \\cong \\frac{C(t_i, w_i)}{C(t_i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tagowanie jako dekodowanie\n",
    "\n",
    "Dekodowanie: majc na wejciu cig obserwacji $O = o_1, o_2, \\cdots, o_T$ nale偶y znale藕 najbardziej prawdopodobn sekwencj stan贸w $Q=q_1, q_2, \\cdots, q_T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\hat t^{n}_{1} = \\textrm{argmax}_{t_1^n}P(t_1^n|w_1^n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\hat t^{n}_{1} = \\textrm{argmax}_{t_1^n}\\frac{P(w_1^n|t_1^n)P(t_1^n)}{P(w_1^n)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\hat t^{n}_{1} = \\textrm{argmax}_{t_1^n}P(w_1^n|t_1^n)P(t_1^n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$P(w_1^n|t_1^n) = \\prod_{i=1}^{n}P(w_i|t_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$P(t_1^n) = \\prod_{i=1}^{n}P(t_i|t_{i-1})$; $P(t_1|t_0) = \\pi(t_1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\hat t^{n}_{1} = \\textrm{argmax}_{t_1^n}P(t_1^n|w_1^n) \\cong \\textrm{argmax}_{t_1^n}\\prod_{i=1}^{n}\\overbrace{P(w_i|t_i)}^{\\textrm{emisja}} \n",
    "\\overbrace{P(t_i|t_{i-1})}^{\\textrm{przejcie}} $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorytm tagowania wykorzystujcy ukryty model Markowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"img/viterbi.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Macierz prawdopodobiestw\n",
    "\n",
    "<center><img src=\"img/viterbi-path.png\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:18:42.244393Z",
     "start_time": "2023-10-24T16:18:42.102471Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi(observations, states, words, initial_p, transition_p, emmision_p):\n",
    "    probs = np.zeros((len(observations), len(states)))\n",
    "    pointers = np.zeros((len(observations), len(states)))\n",
    "    word_idx = words.index(observations[0])\n",
    "    for idx, state in enumerate(states):\n",
    "        probs[0][idx] = initial_p[idx] * emmision_p[idx][word_idx]\n",
    "        pointers[0][idx] = -1\n",
    "    for o_idx, word in enumerate(observations[1:], 1):\n",
    "        word_idx = words.index(observations[o_idx])\n",
    "        for c_idx, c_state in enumerate(states):\n",
    "            max_value, max_idx = -1, -1\n",
    "            for p_idx, p_state in enumerate(states):\n",
    "                value = probs[o_idx-1][p_idx] * transition_p[p_idx][c_idx]\n",
    "                if(value > max_value):\n",
    "                    max_value = value\n",
    "                    max_idx = p_idx\n",
    "            probs[o_idx][c_idx] = max_value * emmision_p[c_idx][word_idx]\n",
    "            pointers[o_idx][c_idx] = max_idx\n",
    "    max_value = max(probs[-1])\n",
    "    \n",
    "    path = []\n",
    "    for idx, word in reversed(list(enumerate(observations))):\n",
    "        path.insert(0, states[probs[idx].argmax(0)])\n",
    "    return path, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:18:43.573731Z",
     "start_time": "2023-10-24T16:18:43.558020Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['DT', 'NN', 'VB'], 0.129024)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [\"a\", \"dog\", \"barks\"]\n",
    "states = [\"NN\", \"DT\", \"VB\"]\n",
    "initial_p = [0.2, 0.6, 0.2]\n",
    "transition_p = [\n",
    "    [0.3, 0.1, 0.6],   # from NN\n",
    "    [0.7, 0.1, 0.2],   # from DT\n",
    "    [0.4, 0.4, 0.2]    # from VB\n",
    "]\n",
    "emmision_p = [\n",
    "    [0.1, 0.8, 0.1],   # from NN\n",
    "    [0.8, 0.1, 0.1],   # from DT\n",
    "    [0.1, 0.1, 0.8]    # from VB\n",
    "]\n",
    "viterbi(sequence, states, sequence, initial_p, transition_p, emmision_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wyszukiwanie wizkowe (beam search)\n",
    "\n",
    "<center><img src=\"img/beam-search.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model Markowa o maksymalnej entropii (Maximum-entropy Markov Model MEMM)\n",
    "\n",
    "### HMM\n",
    "\n",
    "$\\hat t^{n}_{1} \\cong \\textrm{argmax}_{t_1^n}\\prod_{i=1}^{n}\\overbrace{P(w_i|t_i)}^{\\textrm{emisja}} \n",
    "\\overbrace{P(t_i|t_{i-1})}^{\\textrm{przejcie}} $ \n",
    "\n",
    "### MEMM\n",
    "\n",
    "$\\hat t^{n}_{1} \\cong \\textrm{argmax}_{t_1^n}\\prod_{i=1}^{n}P(t_i|w_i, t_{i-1}) $ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* MEMM mo偶e uwzgldnia wiele r贸偶nych cech, o dowolnej komplikacji\n",
    "* Okrelenie P realizowane jest za pomoc regresji logistycznej\n",
    "* Mo偶liwa jest realizacja dw贸ch przej przez te same dane, co pozwala u偶y informacji o nastpnym tagu, w drugim przejciu\n",
    "* dekodowanie mo偶e by zachanne, ale znacznie lepiej sprawdza si algorytm Viterbiego!\n",
    "* istniej jeszcze mocniejsze algorytmy, CRF i sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cechy wykorzystywane przez MEMM \n",
    "\n",
    "<center><img src=\"img/memm.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Taggery dla j. polskiego\n",
    "\n",
    "* Toygger - http://mozart.ipipan.waw.pl/~kkrasnowska/PolEval/src/\n",
    "* KRNNT - https://github.com/kwrobel-nlp/krnnt\n",
    "* COMBO - https://github.com/360er0/COMBO\n",
    "* Stanford NLP - https://stanfordnlp.github.io/stanfordnlp/installation_download.html\n",
    "* Concraft - https://github.com/kawu/concraft-pl\n",
    "* KFTT - https://github.com/kwrobel-nlp/kftt\n",
    "* SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Model BERT, a tagowanie\n",
    "\n",
    "<center>\n",
    "    <img src=\"img/mlm.png\"/>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Literatura \n",
    "\n",
    "[Speech and Language Processing. Daniel Jurafsky & James H. Martin, chapter 8](https://web.stanford.edu/~jurafsky/slp3/8.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/two_tee.jpg\"/>\n",
    "    </center>\n",
    "\n",
    "https://demotywatory.pl/62081/Two-tea-to-room-two-two-"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
